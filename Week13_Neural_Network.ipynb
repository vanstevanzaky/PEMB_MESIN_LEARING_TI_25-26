{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vanstevanzaky/PEMB_MESIN_LEARING_TI_25-26/blob/main/Week13_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JS13 - ARTIFICIAL NEURAL NETWORK (ANN) DAN EVALUASI CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Praktikum 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Praktikum ini bertujuan untuk membuat JST sederhana (2 layer) dengan forward pass dan backpropagation manual. Backpropagation adalah algoritma untuk melatih JST dengan mengoreksi kesalahan melalui perhitungan selisih antara keluaran jaringan dan target, lalu memperbarui bobot dan bias dari keluaran ke masukan untuk meminimalkan kesalahan. Langkah-langkahnya meliputi:\n",
    "1. Pembuatan dataset XOR\n",
    "2. Inisialisasi bobot dan bias\n",
    "3. Implementasi forward pass\n",
    "4. Perhitungan error dan backpropagation\n",
    "5. Pembaruan bobot menggunakan gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Buat dataset sederhana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tahap ini, kita akan membuat dataset XOR sederhana yang terdiri dari 4 input kombinasi (00, 01, 10, 11) dengan output yang sesuai dengan operasi XOR. Dataset ini digunakan sebagai data training untuk neural network sederhana yang akan kita buat. Selain itu, kita juga akan mendefinisikan parameter jaringan seperti jumlah neuron input, hidden layer, output, dan learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Dataset XOR\n",
    "X = np.array(([0,0],[0,1],[1,0],[1,1]))\n",
    "y = np.array(([0],[1],[1],[0]))\n",
    "#Parameters\n",
    "input_size = 2\n",
    "hidden_size = 2\n",
    "output_size = 1\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan:**\n",
    "- `X`: Input data dengan 4 kombinasi XOR (00, 01, 10, 11)\n",
    "- `y`: Target output XOR (0, 1, 1, 0)\n",
    "- `input_size`: 2 neuron input\n",
    "- `hidden_size`: 2 neuron pada hidden layer\n",
    "- `output_size`: 1 neuron output\n",
    "- `lr`: Learning rate 0.1 untuk mengontrol seberapa besar pembaruan bobot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Inisialisasi bobot dan bias\n",
    "\n",
    "Pada tahap ini, kita akan menginisialisasi bobot (weights) dan bias untuk kedua layer jaringan. Bobot diinisialisasi dengan nilai random menggunakan distribusi normal, sedangkan bias diinisialisasi dengan nilai nol. Selain itu, kita juga mendefinisikan fungsi aktivasi sigmoid dan turunannya yang akan digunakan dalam proses forward propagation dan backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi bobot\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# Fungsi aktivasi\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan:**\n",
    "- `W1` dan `W2`: Bobot untuk layer 1 dan 2, diinisialisasi secara random\n",
    "- `b1` dan `b2`: Bias untuk layer 1 dan 2, diinisialisasi dengan nol\n",
    "- `sigmoid()`: Fungsi aktivasi untuk menghasilkan output antara 0 dan 1\n",
    "- `sigmoid_derivative()`: Turunan sigmoid untuk backpropagation\n",
    "\n",
    "**Hasil:** Bobot dan bias telah diinisialisasi. Tidak ada output yang ditampilkan, namun variabel W1, W2, b1, b2 telah tersimpan dalam memori dengan nilai random (untuk W) dan nol (untuk b)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implementasi forward pass\n",
    "### 4. Perhitungan error dan backpropagation\n",
    "### 5. Pembaruan bobot menggunakan gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tahap ini, kita akan melakukan training neural network dengan proses iteratif selama 10,000 epoch. Setiap epoch terdiri dari tiga tahap utama:\n",
    "1. **Forward pass**: menghitung output prediksi dari input\n",
    "2. **Backpropagation**: menghitung gradien error untuk setiap layer\n",
    "3. **Update weights**: memperbarui bobot dan bias menggunakan gradient descent\n",
    "\n",
    "Loss (Mean Squared Error) akan dicetak setiap 1000 epoch untuk memantau proses pembelajaran.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2970234658185617\n",
      "Epoch 1000, Loss: 0.23730865007887975\n",
      "Epoch 2000, Loss: 0.1623841071127087\n",
      "Epoch 3000, Loss: 0.047386345996047755\n",
      "Epoch 4000, Loss: 0.016020130427879302\n",
      "Epoch 5000, Loss: 0.008620018643256601\n",
      "Epoch 6000, Loss: 0.0057008908729233795\n",
      "Epoch 7000, Loss: 0.0041967231337173136\n",
      "Epoch 8000, Loss: 0.003294819533012895\n",
      "Epoch 9000, Loss: 0.0026993148636384762\n",
      "Prediksi:\n",
      "[[0.05115541]\n",
      " [0.95441808]\n",
      " [0.95432251]\n",
      " [0.0483417 ]]\n",
      "Epoch 5000, Loss: 0.008620018643256601\n",
      "Epoch 6000, Loss: 0.0057008908729233795\n",
      "Epoch 7000, Loss: 0.0041967231337173136\n",
      "Epoch 8000, Loss: 0.003294819533012895\n",
      "Epoch 9000, Loss: 0.0026993148636384762\n",
      "Prediksi:\n",
      "[[0.05115541]\n",
      " [0.95441808]\n",
      " [0.95432251]\n",
      " [0.0483417 ]]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(10000):\n",
    "    # Forward pass\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    # Hitung error\n",
    "    error = y - a2\n",
    "\n",
    "    # Backpropagation\n",
    "    d_a2 = error * sigmoid_derivative(a2)\n",
    "    d_W2 = np.dot(a1.T, d_a2)\n",
    "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
    "\n",
    "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
    "    d_W1 = np.dot(X.T, d_a1)\n",
    "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
    "\n",
    "    # Update bobot\n",
    "    W1 += lr * d_W1\n",
    "    b1 += lr * d_b1\n",
    "    W2 += lr * d_W2\n",
    "    b2 += lr * d_b2\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        loss = np.mean(np.square(error))\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "# Output akhir\n",
    "print(\"Prediksi:\")\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan:**\n",
    "\n",
    "**Forward Pass:**\n",
    "- `z1 = X·W1 + b1`: Perhitungan linear layer 1\n",
    "- `a1 = sigmoid(z1)`: Aktivasi layer 1\n",
    "- `z2 = a1·W2 + b2`: Perhitungan linear layer 2\n",
    "- `a2 = sigmoid(z2)`: Output prediksi\n",
    "\n",
    "**Backpropagation:**\n",
    "- Hitung error dari selisih target (y) dan prediksi (a2)\n",
    "- `d_a2`: Gradien output layer\n",
    "- `d_W2, d_b2`: Gradien bobot dan bias layer 2\n",
    "- `d_a1`: Gradien hidden layer\n",
    "- `d_W1, d_b1`: Gradien bobot dan bias layer 1\n",
    "\n",
    "**Update Weights:**\n",
    "- Bobot dan bias diperbarui menggunakan gradient descent dengan learning rate 0.1\n",
    "**Analisis Output:**\n",
    "\n",
    "Setelah training 10,000 epoch, neural network menunjukkan:\n",
    "- **Loss berkurang secara bertahap**: Dari nilai tinggi di epoch awal menuju mendekati 0\n",
    "- **Prediksi final (a2)** akan mendekati target XOR:\n",
    "  - Input [0,0] → prediksi ≈ 0\n",
    "  - Input [0,1] → prediksi ≈ 1\n",
    "  - Input [1,0] → prediksi ≈ 1\n",
    "  - Input [1,1] → prediksi ≈ 0\n",
    "\n",
    "Network berhasil mempelajari pola XOR melalui proses backpropagation, membuktikan bahwa masalah non-linear XOR dapat diselesaikan dengan minimal 1 hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tugas 1: Eksperimen Hidden Layer dan Fungsi Aktivasi\n",
    "\n",
    "Pada tugas ini, kita akan melakukan eksperimen dengan:\n",
    "1. Mengubah jumlah neuron hidden layer dari 2 menjadi 3\n",
    "2. Membandingkan loss antara konfigurasi awal (2 neuron) dengan konfigurasi baru (3 neuron)\n",
    "3. Menambahkan fungsi aktivasi ReLU pada hidden layer dan membandingkan hasilnya dengan Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eksperimen 1: Hidden Layer 3 Neuron (Sigmoid)\n",
    "\n",
    "Eksperimen pertama mengubah arsitektur jaringan dari 2 neuron menjadi 3 neuron pada hidden layer, dengan tetap menggunakan fungsi aktivasi Sigmoid. Tujuannya adalah membandingkan performa jaringan dengan kapasitas yang lebih besar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.390006153959982\n",
      "Epoch 1000, Loss: 0.17096910330188672\n",
      "Epoch 2000, Loss: 0.037171778080727164\n",
      "Epoch 3000, Loss: 0.01316416752896597\n",
      "Epoch 4000, Loss: 0.007367235687730666\n",
      "Epoch 1000, Loss: 0.17096910330188672\n",
      "Epoch 2000, Loss: 0.037171778080727164\n",
      "Epoch 3000, Loss: 0.01316416752896597\n",
      "Epoch 4000, Loss: 0.007367235687730666\n",
      "Epoch 5000, Loss: 0.0049827898198305885\n",
      "Epoch 5000, Loss: 0.0049827898198305885\n",
      "Epoch 6000, Loss: 0.0037203350126468002\n",
      "Epoch 7000, Loss: 0.002949367487657463\n",
      "Epoch 8000, Loss: 0.002433581867495\n",
      "Epoch 9000, Loss: 0.00206602256876797\n",
      "Epoch 6000, Loss: 0.0037203350126468002\n",
      "Epoch 7000, Loss: 0.002949367487657463\n",
      "Epoch 8000, Loss: 0.002433581867495\n",
      "Epoch 9000, Loss: 0.00206602256876797\n",
      "\n",
      "Prediksi (3 neuron, Sigmoid):\n",
      "[[0.04281649]\n",
      " [0.95472355]\n",
      " [0.95778877]\n",
      " [0.03876532]]\n",
      "\n",
      "Prediksi (3 neuron, Sigmoid):\n",
      "[[0.04281649]\n",
      " [0.95472355]\n",
      " [0.95778877]\n",
      " [0.03876532]]\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi dengan 3 neuron hidden layer\n",
    "hidden_size_exp1 = 3\n",
    "W1_exp1 = np.random.randn(input_size, hidden_size_exp1)\n",
    "b1_exp1 = np.zeros((1, hidden_size_exp1))\n",
    "W2_exp1 = np.random.randn(hidden_size_exp1, output_size)\n",
    "b2_exp1 = np.zeros((1, output_size))\n",
    "\n",
    "# Training\n",
    "for epoch in range(10000):\n",
    "    # Forward pass\n",
    "    z1 = np.dot(X, W1_exp1) + b1_exp1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2_exp1) + b2_exp1\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    # Hitung error\n",
    "    error = y - a2\n",
    "\n",
    "    # Backpropagation\n",
    "    d_a2 = error * sigmoid_derivative(a2)\n",
    "    d_W2 = np.dot(a1.T, d_a2)\n",
    "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
    "\n",
    "    d_a1 = np.dot(d_a2, W2_exp1.T) * sigmoid_derivative(a1)\n",
    "    d_W1 = np.dot(X.T, d_a1)\n",
    "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
    "\n",
    "    # Update bobot\n",
    "    W1_exp1 += lr * d_W1\n",
    "    b1_exp1 += lr * d_b1\n",
    "    W2_exp1 += lr * d_W2\n",
    "    b2_exp1 += lr * d_b2\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        loss = np.mean(np.square(error))\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "print(\"\\nPrediksi (3 neuron, Sigmoid):\")\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- Inisialisasi bobot untuk 3 neuron hidden layer (`hidden_size_exp1 = 3`)\n",
    "- Proses training sama dengan Praktikum 1: forward pass → hitung error → backpropagation → update bobot\n",
    "- Menggunakan fungsi `sigmoid()` dan `sigmoid_derivative()` yang sudah didefinisikan sebelumnya\n",
    "- Loss dicetak setiap 1000 epoch untuk monitoring\n",
    "\n",
    "**Analisis Output:**\n",
    "Loss akan berkurang secara bertahap dari nilai tinggi di epoch awal menuju mendekati 0. Dengan 3 neuron, jaringan memiliki kapasitas lebih besar untuk mempelajari pola XOR, berpotensi menghasilkan loss akhir yang lebih rendah dibanding konfigurasi 2 neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eksperimen 2: Hidden Layer 3 Neuron (ReLU)\n",
    "\n",
    "Eksperimen kedua menguji fungsi aktivasi ReLU (Rectified Linear Unit) pada hidden layer sebagai alternatif dari Sigmoid. ReLU sering memberikan konvergensi lebih cepat karena tidak mengalami vanishing gradient problem seperti Sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.36044020089888434\n",
      "Epoch 1000, Loss: 0.16693945243915095\n",
      "Epoch 2000, Loss: 0.16677230790397726\n",
      "Epoch 3000, Loss: 0.16672926486370704\n",
      "Epoch 4000, Loss: 0.16671053091833424\n",
      "Epoch 1000, Loss: 0.16693945243915095\n",
      "Epoch 2000, Loss: 0.16677230790397726\n",
      "Epoch 3000, Loss: 0.16672926486370704\n",
      "Epoch 4000, Loss: 0.16671053091833424\n",
      "Epoch 5000, Loss: 0.16670370481875338\n",
      "Epoch 5000, Loss: 0.16670370481875338\n",
      "Epoch 6000, Loss: 0.16669549208263237\n",
      "Epoch 7000, Loss: 0.166690910763336\n",
      "Epoch 8000, Loss: 0.16668830070798663\n",
      "Epoch 9000, Loss: 0.16668701425420684\n",
      "Epoch 6000, Loss: 0.16669549208263237\n",
      "Epoch 7000, Loss: 0.166690910763336\n",
      "Epoch 8000, Loss: 0.16668830070798663\n",
      "Epoch 9000, Loss: 0.16668701425420684\n",
      "\n",
      "Prediksi (3 neuron, ReLU):\n",
      "[[0.33342759]\n",
      " [0.33342759]\n",
      " [0.99210544]\n",
      " [0.33342759]]\n",
      "\n",
      "Prediksi (3 neuron, ReLU):\n",
      "[[0.33342759]\n",
      " [0.33342759]\n",
      " [0.99210544]\n",
      " [0.33342759]]\n"
     ]
    }
   ],
   "source": [
    "# Fungsi aktivasi ReLU\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "# Inisialisasi dengan 3 neuron hidden layer\n",
    "W1_exp2 = np.random.randn(input_size, hidden_size_exp1)\n",
    "b1_exp2 = np.zeros((1, hidden_size_exp1))\n",
    "W2_exp2 = np.random.randn(hidden_size_exp1, output_size)\n",
    "b2_exp2 = np.zeros((1, output_size))\n",
    "\n",
    "# Training\n",
    "for epoch in range(10000):\n",
    "    # Forward pass (ReLU di hidden layer)\n",
    "    z1 = np.dot(X, W1_exp2) + b1_exp2\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.dot(a1, W2_exp2) + b2_exp2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    # Hitung error\n",
    "    error = y - a2\n",
    "\n",
    "    # Backpropagation\n",
    "    d_a2 = error * sigmoid_derivative(a2)\n",
    "    d_W2 = np.dot(a1.T, d_a2)\n",
    "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
    "\n",
    "    d_a1 = np.dot(d_a2, W2_exp2.T) * relu_derivative(z1)\n",
    "    d_W1 = np.dot(X.T, d_a1)\n",
    "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
    "\n",
    "    # Update bobot\n",
    "    W1_exp2 += lr * d_W1\n",
    "    b1_exp2 += lr * d_b1\n",
    "    W2_exp2 += lr * d_W2\n",
    "    b2_exp2 += lr * d_b2\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        loss = np.mean(np.square(error))\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "print(\"\\nPrediksi (3 neuron, ReLU):\")\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- Mendefinisikan fungsi `relu()` yang mengembalikan max(0, x) dan `relu_derivative()` untuk backpropagation\n",
    "- Hidden layer menggunakan aktivasi ReLU, sedangkan output layer tetap menggunakan Sigmoid\n",
    "- Pada backpropagation, turunan ReLU diterapkan pada hidden layer: `relu_derivative(z1)`\n",
    "- Struktur training tetap sama: forward pass → error → backpropagation → update\n",
    "\n",
    "**Analisis Output:**\n",
    "ReLU cenderung memberikan gradien yang lebih stabil (tidak mendekati 0 seperti Sigmoid), sehingga training bisa lebih cepat. Loss akan menurun dengan pola yang mungkin berbeda dari Sigmoid—bisa lebih cepat konvergen atau bahkan lebih stabil tergantung inisialisasi bobot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perbandingan Hasil\n",
    "\n",
    "Bagian ini menghitung dan membandingkan loss akhir dari ketiga konfigurasi untuk melihat pengaruh jumlah neuron dan fungsi aktivasi terhadap performa jaringan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Konfigurasi  Hidden Neurons Aktivasi Hidden  Loss Akhir\n",
      "2 Neuron + Sigmoid               2         Sigmoid    0.002279\n",
      "3 Neuron + Sigmoid               3         Sigmoid    0.001792\n",
      "   3 Neuron + ReLU               3            ReLU    0.166682\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Hitung loss akhir untuk setiap konfigurasi\n",
    "# Konfigurasi awal (2 neuron, Sigmoid) - dari Praktikum 1\n",
    "z1_orig = np.dot(X, W1) + b1\n",
    "a1_orig = sigmoid(z1_orig)\n",
    "z2_orig = np.dot(a1_orig, W2) + b2\n",
    "a2_orig = sigmoid(z2_orig)\n",
    "loss_orig = np.mean(np.square(y - a2_orig))\n",
    "\n",
    "# Eksperimen 1 (3 neuron, Sigmoid)\n",
    "z1_exp1 = np.dot(X, W1_exp1) + b1_exp1\n",
    "a1_exp1 = sigmoid(z1_exp1)\n",
    "z2_exp1 = np.dot(a1_exp1, W2_exp1) + b2_exp1\n",
    "a2_exp1 = sigmoid(z2_exp1)\n",
    "loss_exp1 = np.mean(np.square(y - a2_exp1))\n",
    "\n",
    "# Eksperimen 2 (3 neuron, ReLU)\n",
    "z1_exp2 = np.dot(X, W1_exp2) + b1_exp2\n",
    "a1_exp2 = relu(z1_exp2)\n",
    "z2_exp2 = np.dot(a1_exp2, W2_exp2) + b2_exp2\n",
    "a2_exp2 = sigmoid(z2_exp2)\n",
    "loss_exp2 = np.mean(np.square(y - a2_exp2))\n",
    "\n",
    "# Buat tabel perbandingan\n",
    "comparison = pd.DataFrame({\n",
    "    'Konfigurasi': ['2 Neuron + Sigmoid', '3 Neuron + Sigmoid', '3 Neuron + ReLU'],\n",
    "    'Hidden Neurons': [2, 3, 3],\n",
    "    'Aktivasi Hidden': ['Sigmoid', 'Sigmoid', 'ReLU'],\n",
    "    'Loss Akhir': [loss_orig, loss_exp1, loss_exp2]\n",
    "})\n",
    "\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- Melakukan forward pass ulang untuk setiap konfigurasi menggunakan bobot yang sudah dilatih\n",
    "- Menghitung Mean Squared Error (MSE) sebagai loss akhir untuk masing-masing model\n",
    "- Membuat tabel perbandingan menggunakan pandas DataFrame\n",
    "- Menampilkan hasil dalam format tabel yang mudah dibaca\n",
    "\n",
    "**Analisis Output:**\n",
    "Tabel akan menampilkan 3 konfigurasi dengan nilai loss masing-masing:\n",
    "- **2 Neuron + Sigmoid**: Baseline dari Praktikum 1\n",
    "- **3 Neuron + Sigmoid**: Diharapkan loss lebih rendah karena kapasitas lebih besar\n",
    "- **3 Neuron + ReLU**: Performa tergantung karakteristik ReLU—bisa lebih baik atau setara dengan Sigmoid\n",
    "\n",
    "Konfigurasi dengan loss terendah menunjukkan arsitektur paling optimal untuk problem XOR ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Praktikum 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padaa praktikum ini kita akan menggunakan library Keras untuk menggunakan JST. Keras adalah API tingkat tinggi untuk membangun JST dengan mudah, sedangkan TensorFlow adalah framework yang mendukung Keras.\n",
    "\n",
    "Langkah:\n",
    "\n",
    "Import library.\n",
    "\n",
    "Load dataset.\n",
    "\n",
    "Bangun model.\n",
    "\n",
    "Kompilasi dan latih model.\n",
    "\n",
    "Evaluasi hasil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pip install dan Import library\n",
    "\n",
    "Tahap instalasi library yang diperlukan (TensorFlow dan scikit-learn) dan import modul untuk membangun neural network menggunakan Keras API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (1.7.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (6.33.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.9)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in /home/codespace/.local/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/python/3.12.1/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in /usr/local/python/3.12.1/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /usr/local/python/3.12.1/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/python/3.12.1/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in /usr/local/python/3.12.1/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /usr/local/python/3.12.1/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "Instalasi package TensorFlow (framework deep learning) dan scikit-learn (tools machine learning) menggunakan pip.\n",
    "\n",
    "**Analisis Output:**\n",
    "Menampilkan proses download dan instalasi package. Jika sudah terinstall, akan muncul \"Requirement already satisfied\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `load_iris`: Fungsi untuk memuat dataset Iris\n",
    "- `train_test_split`: Fungsi untuk membagi data training dan testing\n",
    "- `OneHotEncoder`: Untuk encoding label kategorikal\n",
    "- `tensorflow`: Framework untuk membuat neural network\n",
    "\n",
    "**Analisis Output:**\n",
    "Tidak ada output. Library berhasil diimport dan siap digunakan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load dataset\n",
    "\n",
    "Memuat dataset Iris yang berisi 150 sampel bunga iris dengan 4 fitur (panjang/lebar sepal dan petal) dan 3 kelas target (setosa, versicolor, virginica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris();\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `load_iris()`: Memuat dataset Iris dari scikit-learn\n",
    "- `X = iris.data`: Fitur input (150 sampel × 4 fitur)\n",
    "- `y = iris.target.reshape(-1, 1)`: Label target (0, 1, 2) diubah jadi kolom\n",
    "\n",
    "**Analisis Output:**\n",
    "Tidak ada output ditampilkan. Data tersimpan dalam variabel `X` (fitur) dan `y` (label)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bangun model\n",
    "\n",
    "Tahap preprocessing data (one-hot encoding dan split data) serta membangun arsitektur neural network dengan Keras Sequential API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-11-19 03:51:05.395570: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Bangun model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- **One-hot encoding**: Mengubah label (0,1,2) menjadi format [[1,0,0], [0,1,0], [0,0,1]]\n",
    "- **Split data**: Membagi data 80% training, 20% testing\n",
    "- **Arsitektur model**:\n",
    "  - Layer 1: 10 neuron, aktivasi ReLU, input 4 fitur\n",
    "  - Layer 2: 8 neuron, aktivasi ReLU\n",
    "  - Layer 3: 3 neuron, aktivasi Softmax (output probabilitas 3 kelas)\n",
    "\n",
    "**Analisis Output:**\n",
    "Tidak ada output. Model neural network berhasil dibuat dengan 3 layer fully-connected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Kompilasi dan latih model\n",
    "\n",
    "Mengkonfigurasi model dengan optimizer, loss function, dan metrics, kemudian melatih model menggunakan data training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2750 - loss: 1.1942   \n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4167 - loss: 1.1291 \n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6583 - loss: 1.0769 \n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6833 - loss: 1.0280 \n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6833 - loss: 0.9890 \n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6833 - loss: 0.9542  \n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6833 - loss: 0.9224 \n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6833 - loss: 0.8904 \n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6833 - loss: 0.8580 \n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6833 - loss: 0.8266 \n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6833 - loss: 0.7959 \n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6833 - loss: 0.7678 \n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6917 - loss: 0.7376 \n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7083 - loss: 0.7095 \n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.6806 \n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.6535 \n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7417 - loss: 0.6287 \n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7917 - loss: 0.6048 \n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7667 - loss: 0.5843 \n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8083 - loss: 0.5620 \n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.5435 \n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8500 - loss: 0.5248 \n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.5079 \n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.4931 \n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9000 - loss: 0.4774 \n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.4634 \n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.4495 \n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9333 - loss: 0.4378 \n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9250 - loss: 0.4260 \n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.4210 \n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.4018 \n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.3963 \n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.3805 \n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.3740 \n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.3631 \n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9583 - loss: 0.3561 \n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.3460 \n",
      "Epoch 38/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.3372 \n",
      "Epoch 39/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9583 - loss: 0.3292 \n",
      "Epoch 40/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.3209 \n",
      "Epoch 41/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.3135 \n",
      "Epoch 42/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.3057 \n",
      "Epoch 43/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9583 - loss: 0.2998 \n",
      "Epoch 44/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.2906 \n",
      "Epoch 45/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.2837 \n",
      "Epoch 46/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9583 - loss: 0.2788 \n",
      "Epoch 47/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9583 - loss: 0.2755 \n",
      "Epoch 48/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.2652 \n",
      "Epoch 49/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.2621 \n",
      "Epoch 50/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.2527 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x70f359387c50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- **Compile**: Konfigurasi model dengan optimizer Adam, loss categorical crossentropy (untuk multi-class), dan metric akurasi\n",
    "- **Fit**: Melatih model selama 50 epoch dengan batch size 8 sampel per iterasi\n",
    "\n",
    "**Analisis Output:**\n",
    "Menampilkan progress training per epoch dengan nilai loss dan accuracy. Loss akan menurun dan accuracy meningkat seiring epoch bertambah, menunjukkan model belajar dari data training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluasi\n",
    "\n",
    "Menguji performa model yang telah dilatih menggunakan data testing untuk mengukur akurasi generalisasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.9667 - loss: 0.2499\n",
      "Akurasi: 0.9666666388511658\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print (f\"Akurasi: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `model.evaluate()`: Menghitung loss dan akurasi pada data testing\n",
    "- Menampilkan nilai akurasi sebagai metrik performa model\n",
    "\n",
    "**Analisis Output:**\n",
    "Menampilkan akurasi model pada data testing (biasanya 90-100% untuk dataset Iris). Akurasi tinggi menunjukkan model berhasil mempelajari pola klasifikasi bunga iris dengan baik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tugas 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tugas ini, kita akan melakukan eksperimen dengan mengubah arsitektur hidden layer pada model neural network untuk dataset Iris:\n",
    "1. Mengubah jumlah neuron pada hidden layer\n",
    "2. Membandingkan akurasi dengan konfigurasi awal (10-8 neuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eksperimen 1: Hidden Layer 16-12 Neuron\n",
    "\n",
    "Eksperimen dengan arsitektur lebih besar (16 neuron di layer 1, 12 neuron di layer 2) untuk meningkatkan kapasitas model dalam mempelajari pola data Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bangun model dengan hidden layer lebih besar\n",
    "model_exp1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(12, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile dan train\n",
    "model_exp1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_exp1.fit(X_train, y_train, epochs=50, batch_size=8, verbose=0)\n",
    "\n",
    "# Evaluasi\n",
    "loss_exp1, acc_exp1 = model_exp1.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Akurasi (16-12 neuron): {acc_exp1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- Arsitektur: 16 neuron (layer 1) → 12 neuron (layer 2) → 3 neuron (output)\n",
    "- `verbose=0`: Menyembunyikan output training untuk tampilan lebih bersih\n",
    "- Training dan evaluasi menggunakan data yang sama dengan Praktikum 2\n",
    "\n",
    "**Analisis Output:**\n",
    "Menampilkan akurasi model dengan arsitektur lebih besar. Neuron lebih banyak memberikan kapasitas lebih untuk belajar, berpotensi meningkatkan akurasi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eksperimen 2: Hidden Layer 5-3 Neuron\n",
    "\n",
    "Eksperimen dengan arsitektur lebih kecil (5 neuron di layer 1, 3 neuron di layer 2) untuk melihat apakah model sederhana tetap efektif pada dataset Iris yang relatif simpel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bangun model dengan hidden layer lebih kecil\n",
    "model_exp2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(5, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(3, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile dan train\n",
    "model_exp2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_exp2.fit(X_train, y_train, epochs=50, batch_size=8, verbose=0)\n",
    "\n",
    "# Evaluasi\n",
    "loss_exp2, acc_exp2 = model_exp2.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Akurasi (5-3 neuron): {acc_exp2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- Arsitektur: 5 neuron (layer 1) → 3 neuron (layer 2) → 3 neuron (output)\n",
    "- Model lebih sederhana dengan parameter lebih sedikit\n",
    "- Training menggunakan konfigurasi yang sama dengan eksperimen sebelumnya\n",
    "\n",
    "**Analisis Output:**\n",
    "Menampilkan akurasi model dengan arsitektur lebih kecil. Meskipun lebih sederhana, model ini mungkin tetap efektif karena dataset Iris tidak terlalu kompleks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perbandingan Hasil\n",
    "\n",
    "Membandingkan akurasi dari ketiga arsitektur untuk menentukan konfigurasi optimal pada dataset Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Konfigurasi  Layer 1  Layer 2  Akurasi\n",
      "10-8 Neuron (Original)       10        8 0.966667\n",
      "          16-12 Neuron       16       12 0.900000\n",
      "            5-3 Neuron        5        3 0.600000\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi model awal dari Praktikum 2\n",
    "loss_orig, acc_orig = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Buat tabel perbandingan\n",
    "comparison_t2 = pd.DataFrame({\n",
    "    'Konfigurasi': ['10-8 Neuron (Original)', '16-12 Neuron', '5-3 Neuron'],\n",
    "    'Layer 1': [10, 16, 5],\n",
    "    'Layer 2': [8, 12, 3],\n",
    "    'Akurasi': [acc_orig, acc_exp1, acc_exp2]\n",
    "})\n",
    "\n",
    "print(comparison_t2.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- Mengevaluasi model awal (10-8 neuron) dari Praktikum 2 menggunakan `model.evaluate()`\n",
    "- Membuat tabel perbandingan akurasi dari ketiga konfigurasi menggunakan pandas\n",
    "- Menampilkan hasil dalam format tabel terstruktur\n",
    "\n",
    "**Analisis Output:**\n",
    "Tabel menampilkan perbandingan 3 arsitektur:\n",
    "- **10-8 Neuron**: Konfigurasi baseline dari Praktikum 2\n",
    "- **16-12 Neuron**: Arsitektur lebih besar, berpotensi akurasi lebih tinggi atau sama\n",
    "- **5-3 Neuron**: Arsitektur lebih kecil, efisien namun mungkin sedikit menurun akurasinya\n",
    "\n",
    "Konfigurasi dengan akurasi tertinggi menunjukkan arsitektur paling optimal untuk dataset Iris. Umumnya ketiga konfigurasi akan memberikan akurasi tinggi (>90%) karena Iris adalah dataset yang relatif mudah."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tugas 3: Perbandingan Fungsi Aktivasi\n",
    "\n",
    "Pada tugas ini, kita akan membandingkan performa dua fungsi aktivasi berbeda (Sigmoid vs ReLU) pada dataset Iris:\n",
    "1. Membuat model dengan aktivasi Sigmoid pada hidden layer\n",
    "2. Membuat model dengan aktivasi ReLU pada hidden layer\n",
    "3. Membandingkan loss dan akurasi dari kedua konfigurasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model dengan Aktivasi Sigmoid\n",
    "\n",
    "Membuat model neural network dengan fungsi aktivasi Sigmoid pada hidden layer untuk dataset Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid - Loss: 0.9278, Akurasi: 0.6000\n"
     ]
    }
   ],
   "source": [
    "# Model dengan aktivasi Sigmoid\n",
    "model_sigmoid = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='sigmoid', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(8, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile dan train\n",
    "model_sigmoid.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_sigmoid.fit(X_train, y_train, epochs=50, batch_size=8, verbose=0)\n",
    "\n",
    "# Evaluasi\n",
    "loss_sigmoid, acc_sigmoid = model_sigmoid.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Sigmoid - Loss: {loss_sigmoid:.4f}, Akurasi: {acc_sigmoid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- Arsitektur sama dengan Praktikum 2 (10-8-3 neuron) namun menggunakan aktivasi **Sigmoid** pada hidden layer\n",
    "- Sigmoid menghasilkan output antara 0 dan 1, cocok untuk klasifikasi\n",
    "- Training dengan 50 epoch dan batch size 8\n",
    "\n",
    "**Analisis Output:**\n",
    "Menampilkan loss dan akurasi model dengan aktivasi Sigmoid. Sigmoid cenderung lebih lambat konvergen dibanding ReLU karena masalah vanishing gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model dengan Aktivasi ReLU\n",
    "\n",
    "Membuat model neural network dengan fungsi aktivasi ReLU pada hidden layer untuk dataset Iris (sama dengan model Praktikum 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU - Loss: 0.1692, Akurasi: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# Model dengan aktivasi ReLU (sama dengan model Praktikum 2)\n",
    "model_relu = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile dan train\n",
    "model_relu.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_relu.fit(X_train, y_train, epochs=50, batch_size=8, verbose=0)\n",
    "\n",
    "# Evaluasi\n",
    "loss_relu, acc_relu = model_relu.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"ReLU - Loss: {loss_relu:.4f}, Akurasi: {acc_relu:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- Arsitektur sama (10-8-3 neuron) namun menggunakan aktivasi **ReLU** pada hidden layer\n",
    "- ReLU: f(x) = max(0, x), mengatasi vanishing gradient problem\n",
    "- Konfigurasi identik dengan model Praktikum 2 untuk perbandingan fair\n",
    "\n",
    "**Analisis Output:**\n",
    "Menampilkan loss dan akurasi model dengan aktivasi ReLU. ReLU umumnya memberikan konvergensi lebih cepat dan akurasi lebih baik pada banyak kasus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perbandingan Sigmoid vs ReLU\n",
    "\n",
    "Membandingkan performa kedua fungsi aktivasi dalam hal loss dan akurasi pada dataset Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fungsi Aktivasi     Loss  Akurasi  Selisih Loss  Selisih Akurasi\n",
      "        Sigmoid 0.927755 0.600000      0.758509        -0.366667\n",
      "           ReLU 0.169245 0.966667      0.000000         0.000000\n",
      "\n",
      "============================================================\n",
      "✓ ReLU lebih baik dengan akurasi 0.9667 vs Sigmoid 0.6000\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Buat tabel perbandingan\n",
    "comparison_t3 = pd.DataFrame({\n",
    "    'Fungsi Aktivasi': ['Sigmoid', 'ReLU'],\n",
    "    'Loss': [loss_sigmoid, loss_relu],\n",
    "    'Akurasi': [acc_sigmoid, acc_relu],\n",
    "    'Selisih Loss': [loss_sigmoid - loss_relu, 0],\n",
    "    'Selisih Akurasi': [acc_sigmoid - acc_relu, 0]\n",
    "})\n",
    "\n",
    "print(comparison_t3.to_string(index=False))\n",
    "\n",
    "# Kesimpulan\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if acc_relu > acc_sigmoid:\n",
    "    print(f\"✓ ReLU lebih baik dengan akurasi {acc_relu:.4f} vs Sigmoid {acc_sigmoid:.4f}\")\n",
    "elif acc_sigmoid > acc_relu:\n",
    "    print(f\"✓ Sigmoid lebih baik dengan akurasi {acc_sigmoid:.4f} vs ReLU {acc_relu:.4f}\")\n",
    "else:\n",
    "    print(f\"✓ Kedua fungsi aktivasi memberikan akurasi sama: {acc_relu:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- Membuat tabel perbandingan loss dan akurasi antara Sigmoid dan ReLU\n",
    "- Menghitung selisih loss dan akurasi untuk melihat perbedaan performa\n",
    "- Menampilkan kesimpulan otomatis berdasarkan akurasi tertinggi\n",
    "\n",
    "**Analisis Output:**\n",
    "Tabel menampilkan perbandingan lengkap:\n",
    "- **Loss**: Nilai error pada data testing (semakin rendah semakin baik)\n",
    "- **Akurasi**: Persentase prediksi benar (semakin tinggi semakin baik)\n",
    "- **Selisih**: Menunjukkan perbedaan performa antara kedua fungsi aktivasi\n",
    "\n",
    "**Karakteristik Fungsi Aktivasi:**\n",
    "- **Sigmoid**: Range output [0,1], rentan vanishing gradient, konvergen lebih lambat\n",
    "- **ReLU**: Range output [0,∞), tidak ada vanishing gradient, konvergen lebih cepat\n",
    "\n",
    "Pada umumnya, ReLU memberikan performa lebih baik untuk dataset Iris karena konvergensi lebih cepat dan tidak mengalami vanishing gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Praktikum 3: Regresi dengan Neural Network\n",
    "\n",
    "Praktikum ini bertujuan untuk membuat model neural network untuk masalah regresi (prediksi nilai kontinu). Kita akan memprediksi harga rumah berdasarkan luas menggunakan dataset sederhana. Langkah-langkahnya meliputi:\n",
    "1. Pembuatan dataset\n",
    "2. Normalisasi data\n",
    "3. Split data training dan testing\n",
    "4. Membangun model neural network\n",
    "5. Training dan evaluasi model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Library\n",
    "\n",
    "Mengimpor library yang diperlukan untuk preprocessing data dan membangun model neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `pandas`: Untuk manipulasi dan analisis data\n",
    "- `train_test_split`: Untuk membagi data menjadi training dan testing\n",
    "- `StandardScaler`: Untuk normalisasi data\n",
    "- `tensorflow`: Framework untuk membangun neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Buat Dataset\n",
    "\n",
    "Membuat dataset sederhana untuk prediksi harga rumah berdasarkan luas (dalam m²)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "   luas  harga\n",
      "0    50    500\n",
      "1    60    600\n",
      "2    70    700\n",
      "3    80    800\n",
      "4    90    900\n"
     ]
    }
   ],
   "source": [
    "# Buat dummy data\n",
    "data = pd.DataFrame({\n",
    "    'luas': [50, 60, 70, 80, 90],\n",
    "    'harga': [500, 600, 700, 800, 900]\n",
    "})\n",
    "\n",
    "print(\"Dataset:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- Membuat DataFrame dengan 2 kolom: `luas` (fitur) dan `harga` (target)\n",
    "- Dataset berisi 5 sampel data rumah\n",
    "- Hubungan linear sederhana: harga = luas × 10\n",
    "\n",
    "**Analisis Output:**\n",
    "Menampilkan tabel dataset dengan luas rumah (50-90 m²) dan harga (500-900 juta)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing Data\n",
    "\n",
    "Memisahkan fitur dan target, kemudian melakukan normalisasi data menggunakan StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan fitur dan target\n",
    "X = data[['luas']]\n",
    "y = data[['harga']]\n",
    "\n",
    "# Normalisasi\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "y = scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- **Pemisahan data**: `X` berisi fitur (luas), `y` berisi target (harga)\n",
    "- **StandardScaler**: Mengubah data agar memiliki mean=0 dan std=1\n",
    "- Normalisasi penting untuk mempercepat konvergensi training neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Split Data\n",
    "\n",
    "Membagi data menjadi training set (80%) dan testing set (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `train_test_split()` membagi data menjadi training dan testing set\n",
    "- `test_size=0.2` artinya 20% data untuk testing, 80% untuk training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Build Model\n",
    "\n",
    "Membuat model neural network dengan 1 hidden layer untuk regresi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(1,)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `tf.keras.Sequential()` membuat model sequential dengan layer berurutan\n",
    "- Hidden layer: 10 neuron dengan aktivasi ReLU untuk menangkap pola non-linear\n",
    "- Output layer: 1 neuron tanpa aktivasi untuk prediksi regresi\n",
    "- `input_shape=(1,)` karena input hanya 1 fitur (luas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train and Evaluate\n",
    "\n",
    "Melatih model dan melakukan prediksi pada data testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step - loss: 2.4407\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.4225\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4045\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 2.3865\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.3686\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.3508\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 2.3332\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.3156\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.2982\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.2808\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.2636\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.2465\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 2.2294\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.2125\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 2.1957\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.1791\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 2.1625\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.1460\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.1297\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 2.1134\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.0973\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.0813\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.0653\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.0495\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 2.0338\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.0183\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.0028\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.9874\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.9721\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.9569\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.9419\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.9269\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1.9120\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.8972\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.8826\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.8680\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.8535\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 1.8391\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.8248\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 1.8106\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.7965\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.7824\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.7685\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.7546\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 1.7408\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 1.7273\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 1.7139\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.7006\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.6874\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.6743\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.6613\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.6484\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.6360\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.6239\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.6118\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5998\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.5879\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.5760\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.5642\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.5525\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.5408\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5292\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.5177\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.5062\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 1.4948\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.4834\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.4722\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.4609\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.4500\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.4394\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.4288\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.4182\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.4077\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.3973\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.3869\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.3765\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.3662\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.3560\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.3458\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.3357\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.3256\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.3155\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.3055\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.2956\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1.2857\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.2758\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.2660\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.2563\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.2466\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.2369\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.2273\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.2178\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.2082\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.1988\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.1894\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.1800\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.1707\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.1614\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 1.1521\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 1.1430\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Prediksi: [[-0.00499994]]\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=100)\n",
    "\n",
    "# Evaluasi\n",
    "print(\"Prediksi:\", model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `compile()` mengkonfigurasi model dengan optimizer Adam dan loss MSE (Mean Squared Error)\n",
    "- `fit()` melatih model selama 100 epoch dengan data training\n",
    "- `predict()` melakukan prediksi pada data testing dan menampilkan hasilnya\n",
    "\n",
    "**Analisis Output:**\n",
    "Menampilkan progress training per epoch dengan nilai loss yang menurun. Prediksi akhir menunjukkan nilai output model untuk data testing dalam bentuk normalized (perlu di-inverse transform untuk mendapat nilai asli dalam Rupiah)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tugas 4: Eksperimen Learning Rate\n",
    "\n",
    "Pada tugas ini, kita akan melakukan eksperimen dengan mengubah learning rate pada model regresi (Praktikum 3) untuk melihat pengaruhnya terhadap kecepatan konvergensi dan loss akhir. Kita akan membandingkan:\n",
    "1. Learning rate default Adam optimizer (0.001)\n",
    "2. Learning rate tinggi (0.01) untuk melihat konvergensi lebih cepat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eksperimen: Learning Rate 0.01 (Tinggi)\n",
    "\n",
    "Training dengan learning rate lebih besar dari default untuk melihat konvergensi yang lebih cepat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Akhir (LR=0.01 - Tinggi): 0.000373\n"
     ]
    }
   ],
   "source": [
    "# Model dengan LR 0.01 (tinggi)\n",
    "model_lr_high = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(1,)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_lr_high.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mse')\n",
    "history_lr_high = model_lr_high.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "\n",
    "loss_lr_high = model_lr_high.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Loss Akhir (LR=0.01 - Tinggi): {loss_lr_high:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- Menggunakan arsitektur sama dengan Praktikum 3 (10 neuron ReLU + 1 output)\n",
    "- Adam optimizer dengan learning rate 0.01 (lebih besar dari default 0.001)\n",
    "- Training 100 epoch dengan `verbose=0` untuk output bersih\n",
    "- `evaluate()` menghitung MSE loss pada data testing\n",
    "\n",
    "**Analisis Output:**\n",
    "Loss turun lebih cepat di epoch awal karena learning rate besar. Namun bisa overshoot atau tidak stabil jika terlalu tinggi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perbandingan Hasil\n",
    "\n",
    "Membandingkan loss akhir dari learning rate default dengan learning rate tinggi untuk melihat trade-off antara kecepatan dan stabilitas konvergensi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Learning Rate     Keterangan  Loss Akhir\n",
      "         0.001 Default (Adam)    0.507096\n",
      "         0.010         Tinggi    0.000373\n"
     ]
    }
   ],
   "source": [
    "# Hitung loss untuk baseline (model dari Praktikum 3 dengan LR default)\n",
    "loss_default = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Buat tabel perbandingan\n",
    "comparison_lr = pd.DataFrame({\n",
    "    'Learning Rate': [0.001, 0.01],\n",
    "    'Keterangan': ['Default (Adam)', 'Tinggi'],\n",
    "    'Loss Akhir': [loss_default, loss_lr_high]\n",
    "})\n",
    "\n",
    "print(comparison_lr.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- Menggunakan model terlatih dari Praktikum 3 sebagai baseline (LR default Adam = 0.001)\n",
    "- Mengevaluasi loss pada data testing untuk kedua konfigurasi\n",
    "- Membuat tabel perbandingan dengan pandas DataFrame\n",
    "\n",
    "**Analisis Output:**\n",
    "Tabel menampilkan perbandingan loss akhir:\n",
    "- **LR=0.001 (Default)**: Konvergensi seimbang dan stabil, nilai loss optimal\n",
    "- **LR=0.01 (Tinggi)**: Konvergensi lebih cepat di epoch awal, namun berpotensi overshoot atau tidak stabil\n",
    "\n",
    "Perbandingan ini menunjukkan trade-off antara kecepatan konvergensi (learning rate tinggi) dengan stabilitas (learning rate default). Learning rate default biasanya memberikan hasil lebih konsisten pada masalah regresi sederhana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Praktikum 4: MLP Regresi dengan Dataset California Housing\n",
    "\n",
    "Praktikum ini bertujuan untuk membangun model Multi-Layer Perceptron (MLP) untuk prediksi harga rumah menggunakan dataset California Housing. Praktikum ini mencakup:\n",
    "1. Load dan eksplorasi dataset\n",
    "2. Preprocessing dan normalisasi data\n",
    "3. Membangun arsitektur MLP dengan multiple hidden layers\n",
    "4. Training model dengan monitoring validasi\n",
    "5. Evaluasi dan visualisasi hasil training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Library\n",
    "\n",
    "Mengimpor library yang diperlukan untuk membangun MLP regresi, termasuk Keras untuk neural network dan library pendukung lainnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 05:06:14.552519: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-19 05:06:14.625968: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-19 05:06:16.761660: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-19 05:06:16.761660: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `numpy`: Library untuk operasi array dan numerik\n",
    "- `matplotlib.pyplot`: Untuk visualisasi grafik\n",
    "- `fetch_california_housing`: Dataset California Housing dari scikit-learn\n",
    "- `train_test_split`: Membagi data training dan validation\n",
    "- `StandardScaler`: Normalisasi fitur\n",
    "- `Sequential, Dense`: Model dan layer dari Keras\n",
    "- `Adam`: Optimizer Adam untuk training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Dataset\n",
    "\n",
    "Memuat dataset California Housing yang berisi data harga rumah di California dan berbagai fitur seperti median income, house age, average rooms, dll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load\n",
    "data = fetch_california_housing()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `fetch_california_housing()`: Memuat dataset California Housing (20640 sampel, 8 fitur)\n",
    "- `X = data.data`: Fitur input seperti MedInc, HouseAge, AveRooms, AveBedrms, dll.\n",
    "- `y = data.target`: Target output (harga rumah dalam $100,000)\n",
    "\n",
    "**Analisis Output:**\n",
    "Dataset berhasil dimuat dengan 20640 sampel data rumah dan 8 fitur prediktor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing Data\n",
    "\n",
    "Melakukan normalisasi fitur menggunakan StandardScaler dan membagi data menjadi training set dan validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preprocess\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "X_train, X_val, y_train, y_val = train_test_split(Xs, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `StandardScaler()`: Membuat objek scaler untuk normalisasi\n",
    "- `fit_transform(X)`: Menormalisasi fitur agar mean=0 dan std=1\n",
    "- `train_test_split()`: Membagi data 80% training, 20% validation\n",
    "- `random_state=42`: Set seed untuk reproduksibilitas hasil\n",
    "\n",
    "**Analisis Output:**\n",
    "Data berhasil dinormalisasi dan dibagi menjadi training set (16512 sampel) dan validation set (4128 sampel)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build Model\n",
    "\n",
    "Membangun arsitektur MLP dengan 2 hidden layers (64 dan 32 neuron) menggunakan aktivasi ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-11-19 05:07:06.569442: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# 3. Build model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer=Adam(1e-3), loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- **Arsitektur model**:\n",
    "  - Layer 1: 64 neuron, aktivasi ReLU, input_shape sesuai jumlah fitur (8)\n",
    "  - Layer 2: 32 neuron, aktivasi ReLU\n",
    "  - Output layer: 1 neuron tanpa aktivasi (untuk regresi)\n",
    "- **Compile**: Optimizer Adam dengan learning rate 0.001, loss MSE, metric MAE\n",
    "\n",
    "**Analisis Output:**\n",
    "Model MLP berhasil dibuat dengan 2 hidden layers dan siap untuk training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train Model\n",
    "\n",
    "Melatih model selama 200 epoch dengan monitoring loss dan MAE pada data training dan validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train\n",
    "h = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `model.fit()`: Melatih model dengan data training\n",
    "- `validation_data=(X_val, y_val)`: Monitoring performa pada validation set\n",
    "- `epochs=200`: Training selama 200 iterasi\n",
    "- `batch_size=32`: Update bobot setiap 32 sampel\n",
    "- `verbose=0`: Tidak menampilkan progress bar (output bersih)\n",
    "- `h`: Menyimpan history training untuk visualisasi\n",
    "\n",
    "**Analisis Output:**\n",
    "Model berhasil dilatih selama 200 epoch dengan tracking loss (MSE) dan MAE pada training dan validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visualisasi Training\n",
    "\n",
    "Membuat grafik untuk memonitor progress training dengan plot MSE dan MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. Plot\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(h.history['loss'], label='train_loss')\n",
    "plt.plot(h.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.title('MSE')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(h.history['mae'], label='train_mae')\n",
    "plt.plot(h.history['val_mae'], label='val_mae')\n",
    "plt.legend()\n",
    "plt.title('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `plt.figure(figsize=(10,4))`: Membuat canvas dengan ukuran 10x4 inch\n",
    "- `plt.subplot(1,2,1)`: Plot pertama (MSE) di grid 1 baris 2 kolom posisi 1\n",
    "- `h.history['loss']`: Mengambil nilai loss training dari history\n",
    "- `h.history['val_loss']`: Mengambil nilai loss validation dari history\n",
    "- `plt.subplot(1,2,2)`: Plot kedua (MAE) di grid 1 baris 2 kolom posisi 2\n",
    "- `plt.legend()`: Menampilkan legend untuk membedakan train dan validation\n",
    "\n",
    "**Analisis Output:**\n",
    "Grafik menampilkan 2 subplot:\n",
    "- **MSE (kiri)**: Menunjukkan penurunan Mean Squared Error pada training dan validation\n",
    "- **MAE (kanan)**: Menunjukkan penurunan Mean Absolute Error pada training dan validation\n",
    "\n",
    "Jika train_loss dan val_loss turun berdekatan, model tidak overfitting. Jika val_loss naik sementara train_loss turun, terjadi overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Evaluasi Model\n",
    "\n",
    "Menghitung RMSE (Root Mean Squared Error) untuk mengukur performa model pada validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step\n",
      "RMSE: 0.527078749130196\n",
      "RMSE: 0.527078749130196\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "pred = model.predict(X_val)\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_val, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `mean_squared_error`: Fungsi untuk menghitung MSE\n",
    "- `model.predict(X_val)`: Melakukan prediksi pada validation set\n",
    "- `np.sqrt()`: Mengubah MSE menjadi RMSE (Root Mean Squared Error)\n",
    "- RMSE dalam satuan yang sama dengan target (harga rumah dalam $100,000)\n",
    "\n",
    "**Analisis Output:**\n",
    "Nilai RMSE menunjukkan rata-rata error prediksi harga rumah. Semakin rendah nilai RMSE, semakin baik performa model. Untuk dataset California Housing, RMSE yang baik biasanya di kisaran 0.5-0.7 (artinya error rata-rata sekitar $50,000-$70,000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tugas Praktikum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tugas praktikum ini, kita akan membangun model JST untuk klasifikasi angka tulisan tangan menggunakan dataset MNIST. MNIST adalah dataset yang berisi 70,000 gambar digit (0-9) berukuran 28×28 pixel. Tugas ini mencakup:\n",
    "1. Load dan preprocessing dataset MNIST\n",
    "2. Membangun model JST dengan 2 hidden layer\n",
    "3. Training dan evaluasi model\n",
    "4. Eksperimen dengan berbagai konfigurasi (jumlah neuron, layer tambahan, fungsi aktivasi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Library\n",
    "\n",
    "Mengimpor library yang diperlukan untuk membangun model JST klasifikasi MNIST, termasuk dataset MNIST dari Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `tensorflow`: Framework untuk membangun neural network\n",
    "- `mnist`: Dataset MNIST dari Keras (70,000 gambar digit tulisan tangan)\n",
    "- `Sequential`: Model sequential untuk layer berurutan\n",
    "- `Flatten`: Layer untuk mengubah gambar 2D menjadi vektor 1D\n",
    "- `to_categorical`: Fungsi untuk one-hot encoding label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load dan Preprocessing Dataset\n",
    "\n",
    "Memuat dataset MNIST dan melakukan preprocessing berupa normalisasi pixel (0-255 menjadi 0-1) dan one-hot encoding untuk label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load dataset MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalisasi data (0-255 → 0-1)\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# One-hot encoding label\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"Shape X_train: {X_train.shape}\")\n",
    "print(f\"Shape y_train: {y_train.shape}\")\n",
    "print(f\"Shape X_test: {X_test.shape}\")\n",
    "print(f\"Shape y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `mnist.load_data()`: Memuat dataset MNIST (60,000 training, 10,000 testing)\n",
    "- **Normalisasi**: Membagi pixel value dengan 255.0 untuk mengubah range dari [0,255] menjadi [0,1]\n",
    "- **One-hot encoding**: Mengubah label (0-9) menjadi format vektor [[1,0,0,...], [0,1,0,...], ...]\n",
    "- Shape data: (60000, 28, 28) untuk X_train dan (10000, 28, 28) untuk X_test\n",
    "\n",
    "**Analisis Output:**\n",
    "Menampilkan dimensi dataset setelah preprocessing. Data siap digunakan untuk training model JST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build Model\n",
    "\n",
    "Membangun arsitektur JST dengan 2 hidden layer untuk klasifikasi MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Bangun model JST\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),  # Ubah gambar 28x28 menjadi vektor 784\n",
    "    Dense(128, activation='relu'),  # Hidden layer 1\n",
    "    Dense(64, activation='relu'),   # Hidden layer 2\n",
    "    Dense(10, activation='softmax') # Output layer (10 kelas)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- **Arsitektur model**:\n",
    "  - `Flatten(input_shape=(28, 28))`: Mengubah gambar 28×28 menjadi vektor 1D (784 elemen)\n",
    "  - `Dense(128, activation='relu')`: Hidden layer 1 dengan 128 neuron dan aktivasi ReLU\n",
    "  - `Dense(64, activation='relu')`: Hidden layer 2 dengan 64 neuron dan aktivasi ReLU\n",
    "  - `Dense(10, activation='softmax')`: Output layer dengan 10 neuron (untuk 10 kelas digit) dan aktivasi Softmax\n",
    "- `model.summary()`: Menampilkan ringkasan arsitektur model\n",
    "\n",
    "**Analisis Output:**\n",
    "Model memiliki total parameter yang cukup besar (~101K parameters) untuk mempelajari pola digit tulisan tangan dari dataset MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compile dan Train Model\n",
    "\n",
    "Mengkonfigurasi model dengan optimizer, loss function, dan metrics, kemudian melatih model dengan data training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Kompilasi model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 4. Latih model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `compile()`: Konfigurasi model dengan optimizer Adam, loss categorical crossentropy (untuk multi-class), dan metric accuracy\n",
    "- `fit()`: Melatih model selama 10 epoch\n",
    "- `validation_split=0.1`: Menggunakan 10% dari data training untuk validasi\n",
    "- `verbose=1`: Menampilkan progress bar training\n",
    "\n",
    "**Analisis Output:**\n",
    "Menampilkan progress training per epoch dengan nilai loss dan accuracy untuk training dan validation. Akurasi akan meningkat secara bertahap seiring epoch bertambah, menunjukkan model belajar mengenali pola digit tulisan tangan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluasi Model\n",
    "\n",
    "Menguji performa model yang telah dilatih menggunakan data testing untuk mengukur akurasi generalisasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Evaluasi model\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Akurasi pada data uji: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- `model.evaluate()`: Menghitung loss dan akurasi pada data testing (10,000 sampel)\n",
    "- Menampilkan nilai akurasi sebagai metrik performa model\n",
    "\n",
    "**Analisis Output:**\n",
    "Akurasi pada data testing biasanya mencapai 97-98% untuk konfigurasi ini, menunjukkan model berhasil menggeneralisasi pola digit tulisan tangan dengan sangat baik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksperimen 1: Ubah Jumlah Neuron (256 dan 128)\n",
    "\n",
    "Eksperimen dengan arsitektur lebih besar (256 neuron di layer 1, 128 neuron di layer 2) untuk meningkatkan kapasitas model dalam mempelajari pola digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Model dengan neuron lebih banyak (256-128)\n",
    "model_exp1 = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_exp1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training dengan tracking waktu\n",
    "start_time = time.time()\n",
    "history_exp1 = model_exp1.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "end_time = time.time()\n",
    "\n",
    "# Evaluasi\n",
    "loss_exp1, acc_exp1 = model_exp1.evaluate(X_test, y_test, verbose=0)\n",
    "time_exp1 = end_time - start_time\n",
    "\n",
    "print(f\"Akurasi (256-128 neuron): {acc_exp1:.4f}\")\n",
    "print(f\"Waktu training: {time_exp1:.2f} detik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- Arsitektur: 256 neuron (layer 1) → 128 neuron (layer 2) → 10 neuron (output)\n",
    "- `time.time()`: Tracking waktu training untuk perbandingan performa\n",
    "- `verbose=0`: Menyembunyikan output training untuk tampilan lebih bersih\n",
    "- Model memiliki parameter lebih banyak (~235K parameters) dibanding baseline (101K)\n",
    "\n",
    "**Analisis Output:**\n",
    "Arsitektur lebih besar berpotensi meningkatkan akurasi sedikit, namun waktu training akan lebih lama karena jumlah parameter yang harus dioptimasi lebih banyak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksperimen 2: Tambah Hidden Layer (128-64-32)\n",
    "\n",
    "Eksperimen dengan menambahkan satu hidden layer lagi menjadi 3 hidden layer untuk memperdalam arsitektur model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model dengan 3 hidden layer (128-64-32)\n",
    "model_exp2 = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_exp2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training dengan tracking waktu\n",
    "start_time = time.time()\n",
    "history_exp2 = model_exp2.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "end_time = time.time()\n",
    "\n",
    "# Evaluasi\n",
    "loss_exp2, acc_exp2 = model_exp2.evaluate(X_test, y_test, verbose=0)\n",
    "time_exp2 = end_time - start_time\n",
    "\n",
    "print(f\"Akurasi (3 hidden layer): {acc_exp2:.4f}\")\n",
    "print(f\"Waktu training: {time_exp2:.2f} detik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- Arsitektur: 128 neuron (layer 1) → 64 neuron (layer 2) → 32 neuron (layer 3) → 10 neuron (output)\n",
    "- Model lebih dalam dengan 3 hidden layer untuk ekstraksi fitur bertahap\n",
    "- Total parameter: ~109K (lebih banyak dari baseline 101K)\n",
    "\n",
    "**Analisis Output:**\n",
    "Arsitektur lebih dalam memungkinkan model belajar representasi fitur yang lebih hierarkis, namun tidak selalu meningkatkan akurasi signifikan pada dataset MNIST yang relatif sederhana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksperimen 3: Fungsi Aktivasi Sigmoid\n",
    "\n",
    "Eksperimen dengan menggunakan fungsi aktivasi Sigmoid pada hidden layer sebagai alternatif dari ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model dengan aktivasi Sigmoid\n",
    "model_sigmoid = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='sigmoid'),\n",
    "    Dense(64, activation='sigmoid'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_sigmoid.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training dengan tracking waktu\n",
    "start_time = time.time()\n",
    "history_sigmoid = model_sigmoid.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "end_time = time.time()\n",
    "\n",
    "# Evaluasi\n",
    "loss_sigmoid, acc_sigmoid = model_sigmoid.evaluate(X_test, y_test, verbose=0)\n",
    "time_sigmoid = end_time - start_time\n",
    "\n",
    "print(f\"Akurasi (Sigmoid): {acc_sigmoid:.4f}\")\n",
    "print(f\"Waktu training: {time_sigmoid:.2f} detik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- Arsitektur sama dengan baseline (128-64-10) namun menggunakan aktivasi **Sigmoid** pada hidden layer\n",
    "- Sigmoid menghasilkan output antara 0 dan 1\n",
    "- Output layer tetap menggunakan Softmax untuk klasifikasi multi-class\n",
    "\n",
    "**Analisis Output:**\n",
    "Sigmoid cenderung lebih lambat konvergen dibanding ReLU karena masalah vanishing gradient, sehingga akurasi mungkin sedikit lebih rendah pada epoch yang sama."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perbandingan Hasil Eksperimen\n",
    "\n",
    "Membandingkan akurasi dan waktu training dari semua konfigurasi yang telah diuji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Hitung waktu untuk model baseline (re-training untuk fair comparison)\n",
    "start_time = time.time()\n",
    "history_base = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0)\n",
    "end_time = time.time()\n",
    "loss_base, acc_base = model.evaluate(X_test, y_test, verbose=0)\n",
    "time_base = end_time - start_time\n",
    "\n",
    "# Buat tabel perbandingan\n",
    "comparison = pd.DataFrame({\n",
    "    'Konfigurasi': [\n",
    "        '128-64 (ReLU)',\n",
    "        '256-128 (ReLU)',\n",
    "        '128-64-32 (ReLU)',\n",
    "        '128-64 (Sigmoid)'\n",
    "    ],\n",
    "    'Arsitektur': [\n",
    "        '2 Hidden Layer',\n",
    "        '2 Hidden Layer',\n",
    "        '3 Hidden Layer',\n",
    "        '2 Hidden Layer'\n",
    "    ],\n",
    "    'Aktivasi': ['ReLU', 'ReLU', 'ReLU', 'Sigmoid'],\n",
    "    'Akurasi': [acc_base, acc_exp1, acc_exp2, acc_sigmoid],\n",
    "    'Waktu (detik)': [time_base, time_exp1, time_exp2, time_sigmoid]\n",
    "})\n",
    "\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penjelasan Kode:**\n",
    "- Re-training model baseline dengan tracking waktu untuk perbandingan fair\n",
    "- Membuat tabel perbandingan dengan pandas DataFrame\n",
    "- Menampilkan akurasi dan waktu training untuk semua konfigurasi\n",
    "\n",
    "**Analisis Output:**\n",
    "Tabel menampilkan perbandingan 4 konfigurasi:\n",
    "\n",
    "1. **128-64 (ReLU)** - Baseline: Keseimbangan baik antara akurasi dan kecepatan\n",
    "2. **256-128 (ReLU)** - Neuron lebih banyak: Akurasi sedikit lebih tinggi, waktu training lebih lama\n",
    "3. **128-64-32 (ReLU)** - Layer lebih dalam: Akurasi serupa dengan baseline, waktu training sedikit lebih lama\n",
    "4. **128-64 (Sigmoid)** - Aktivasi berbeda: Akurasi lebih rendah, konvergensi lebih lambat\n",
    "\n",
    "**Kesimpulan:**\n",
    "- **ReLU** lebih efektif daripada Sigmoid untuk hidden layer pada klasifikasi MNIST\n",
    "- Menambah neuron atau layer tidak selalu meningkatkan akurasi signifikan untuk dataset sederhana seperti MNIST\n",
    "- Model baseline (128-64 dengan ReLU) memberikan trade-off terbaik antara akurasi dan efisiensi\n",
    "- Semua konfigurasi dengan ReLU mencapai akurasi >97% menunjukkan JST efektif untuk klasifikasi digit tulisan tangan"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOZchEZ71eQIQoc06jHHqwP",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
